---
title: "Actuarial Applications of Deep Learning"
subtitle: "Loss Reserving and Beyond"
author: "Joe Fang, Nicole Foster, and Kevin Kuo"
date: "May 2018"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts", "hygge"]
    lib_dir: static/libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

# Welcome/Introduction

---
# Agenda

- Introduction to Deep Learning

- Hands-on Keras Demo

- Loss Reserving Case Study

- Q+A and Open Discussion

---
# What is Machine Learning?

- A field of computer science that gives computers the ability to "learn" with data, without being explicitly programmed

![](img/machine-learning-features.png)

---
# Why Deep Learning?

- Subset of machine learning

- Often uses a neural network to simulate how the human brain learns

- Performs better than traditional machine learning techniques for large datasets

```{r fig.align='center', out.width='60%', echo=FALSE}
knitr::include_graphics("img/deep-learning.png")
```

---
# What is a Neural Network?

![](img/neural-network.png)

---
# How does a neural network learn?

- Loss Functions

- Gradient Descent

![](img/gradient-descent.png)

---
# What software is available for deep learning?

- Front-end/programming language

    - R, Python

- Interface between front and back end

    - Keras

- Back-end for calculations

    - TensorFlow, Theano

---
# Intro to Keras

- Keras is a high-level neural networks API developed with a focus on enabling fast experimentation

- https://keras.rstudio.com/

---
# MNIST Example

Let's switch to R!

---
# Q&A and Discussion

---
=======
Hello!

---
class: inverse, center, middle

# Loss reserving case study

---

# "Claims liabilities Estimation"

Basically, figure out what we gotta pay in the future due to claims.

---

# Example triangle

```{r}
library(insuranceData)
data(IndustryAuto)
head(IndustryAuto, 12)
```

---

# Actually a triangle

```{r, message = FALSE}
library(tidyverse)
# look at data as of calendar year 2002
data <- IndustryAuto %>%
  rename(ay = Incurral.Year, dev = Development.Year, paid = Claim) %>%
  filter(ay + dev - 1 <= 2002)
# convert to triangle format
data %>%
  spread(dev, paid)
```

---

# Treat this as a predictive modeling problem

Each cell of the triangle is a row in the modeling dataset.

We just need to come up with some predictors

```{r, echo = FALSE}
data %>%
  mutate(predictors = "?!?!") %>%
  head(5)
```

Then we can do something like

```{r, eval = FALSE}
crazy_AI_algorithm(paid ~ predictors, data = data)
```

---

# Introducing DeepTriangle

From the abstract...

> We propose a novel approach for loss reserving based on deep neural networks.
The approach allows for jointly modeling of paid losses and claims outstanding,
and incorporation of heterogenous inputs. We demonstrate the performance of
the models by validating them on publicly available Schedule P data across lines
of business and show that they achieve the performance of existing techniques
while requiring minimal feature engineering and actuarial input.

---

# DeepTriangle

Sounds fancy on paper, but it's really just a neural network.

---

# Data

Schedule P data from [http://www.casact.org/research/index.cfm?fa=loss_reserves_data](http://www.casact.org/research/index.cfm?fa=loss_reserves_data).

10 accident years (1988-1997) of paid and incurred losses, with 10 development lags, from a bunch of companies and lines of business.

---

# Response and predictors

- Response: incremental paid losses and total claims outstanding
- Predictors:
  - Time series of paid losses and case reserves along accident year
  - Time series of paid losses and case reserves along development year
  - Company (because we're using data from all companies simultaneously)

---

# Response

- **Response: incremental paid losses and total claims outstanding**

We're gonna predict both paid loss and claims o/s in the same model, ain't that cool?!

---

# Predictors

- Response: incremental paid losses and total claims outstanding `r emo::ji("thumbsup")`
- **Predictors:**
  - **Time series of paid losses and case reserves along accident year**
  - **Time series of paid losses and case reserves along development year**
  - Company (because we're using data from all companies simultaneously)

---

# Predictors

There's really not much we can use in aggregated data. We also have to follow this rule:

> The information used to derive the predictors for a cell must be available before the calendar period associated with the cell.

I.e. we're not cheating and looking into the future.

=======
# Predictors

Let's see what we mean by "time series of paid losses".

---

# Predictors

Get some incremental numbers

```{r}
incremental_data <- data %>%
  group_by(ay) %>%
  mutate(incremental_paid = paid - lag(paid, default = 0))
incremental_data %>%
  select(-paid) %>%
  spread(dev, incremental_paid)
```

---

# Predictors

Let's say, for example, we want to compute "time series of paid losses along AY" predictor, we'd do something like

```{r}
sample_data_with_paid_history <- incremental_data %>%
  mutate(
    paid_history = map_chr(seq_along(incremental_paid),
                       ~ incremental_paid[0:(.x - 1)] %>%
                         paste0(collapse = ", ")
                       )
  ) %>%
  ungroup() %>%
  filter(ay == 1995) %>%
  select(dev, incremental_paid, paid_history)
```

---

# Predictors

That looks like

```{r, out.width="100%"}
sample_data_with_paid_history
```

---

# Predictors

In DeepTriangle, we do this for both paid loss & case reserve numbers, along both `ay` and `dev`.

---

# Predictors

- **Predictors:**
  - Time series of paid losses and case reserves along accident year `r emo::ji("thumbsup")`
  - Time series of paid losses and case reserves along development year `r emo::ji("thumbsup")`
  - **Company (because we're using data from all companies simultaneously)**

---

# Predictors

Company code is one-hot encoded, e.g. the third company in a collection of $20$ companies would be represented as

```{r}
keras::to_categorical(3, num_classes = 20)
```

---

# Predictors

- Response: incremental paid losses and total claims outstanding `r emo::ji("thumbsup")`
- Predictors:
  - Time series of paid losses and case reserves along accident year `r emo::ji("thumbsup")`
  - Time series of paid losses and case reserves along development year `r emo::ji("thumbsup")`
  - Company (because we're using data from all companies simultaneously) `r emo::ji("thumbsup")`
  
Now that we've gone through the response and predictors, let's talk about the neural network itself!

---

# Architecture

```{r, out.width= "50%", fig.align='center', echo = FALSE}
knitr::include_graphics("figs/nn1.png")
```
